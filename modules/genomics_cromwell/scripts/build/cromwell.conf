# This is an example of how you can use the Google Pipelines API backend
# provider. *This is not a complete configuration file!* The
# content here should be copy pasted into the backend -> providers section
# of cromwell.example.backends/cromwell.examples.conf in the root of the repository.
# You should uncomment lines that you want to define, and read carefully to customize
# the file. If you have any questions, please open an issue at
# https://broadworkbench.atlassian.net/projects/BA/issues

# Documentation
# https://cromwell.readthedocs.io/en/stable/backends/Google/

google {
  application-name = "cromwell"
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    },
    {
      name = "user-service-account"
      scheme = "user_service_account"
    }
  ]
}
# Filesystems available in this Crowmell instance
# They can be enabled individually in the engine.filesystems stanza and in the config.filesystems stanza of backends
# There is a default built-in local filesytem that can also be referenced as "local" as well.
filesystems {
  gcs {
    class = "cromwell.filesystems.gcs.GcsPathBuilderFactory"
  }
}	

engine {
  filesystems {
    gcs {
      auth = "application-default"
    }
  }
}

backend {
  default = GCPBATCH
  

  providers {
    GCPBATCH {
      actor-factory = "cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory"
      config {
        # Google project
        project = "${CROMWELL_PROJECT}"

        # Base bucket for workflow executions
        root = "${CROMWELL_ROOT_BUCKET}"


        # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in Batch API.
        slow-job-warning-time: 24 hours

        # Polling for completion backs-off gradually for slower-running jobs.
        # This is the maximum polling interval (in seconds):
        maximum-polling-interval = 600

        # Optional Dockerhub Credentials. Can be used to access private docker images.
        dockerhub {
          # account = ""
          # token = ""
        }

        # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.
        # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.
        virtual-private-cloud {
          network-name = "projects/${CROMWELL_PROJECT}/global/networks/${CROMWELL_VPC}"
          subnetwork-name = "regions/${CROMWELL_REGION}/subnetworks/${CROMWELL_VPC}"
        }
        # Global pipeline timeout
        # Defaults to 7 days; max 30 days
        # pipeline-timeout = 7 days

        genomics {
          # A reference to an auth defined in the `google` stanza at the top.  This auth is used to create
          # Pipelines and manipulate auth JSONs.
          auth = "application-default"
          
          # Currently Cloud Life Sciences API is available now in more locations for the full list check
          # https://cloud.google.com/life-sciences/docs/concepts/locations
          location = "${CROMWELL_BATCH_LOCATION}"

          // alternative service account to use on the launched compute instance
          // NOTE: If combined with service account authorization, both that serivce account and this service account
          // must be able to read and write to the 'root' GCS path
          compute-service-account = "${CROMWELL_SERVICE_ACCOUNT}"

               
          
          # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service
          # account not owned by the submitting user
          restrict-metadata-access = false

          # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.
          # Parallel composite uploads can result in a significant improvement in delocalization speed for large files
          # but may introduce complexities in downloading such files from GCS, please see
          # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.
          #
          # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off
          # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.
          parallel-composite-upload-threshold="150M"
        }

        filesystems {
          gcs {
            # A reference to a potentially different auth for manipulating files via engine functions.
            auth = "application-default"
            # Google project which will be billed for the requests
            project = "${REQUESTER_PAY_PROJECT}"

            caching {
              # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs
              # Possible values: "copy", "reference". Defaults to "copy"
              # "copy": Copy the output files
              # "reference": DO NOT copy the output files but point to the original output files instead.
              #              Will still make sure than all the original output files exist and are accessible before
              #              going forward with the cache hit.
              duplication-strategy = "copy"
            }
          }
        }

        default-runtime-attributes {
          cpu: 1
          failOnStderr: false
          continueOnReturnCode: 0
          memory: "2048 MB"
          bootDiskSizeGb: 10
          # Allowed to be a String, or a list of Strings
          disks: "local-disk 10 SSD"
          # Worker nodes will be created without External IP address, Private Google Access needs to be enabled to access
          # GCS and Cloud NAT needs to be configured to access Internet resources such as Docker HUB
          noAddress: true
          # Update to 1 to make PVM the default choice unless over-ridden in the task runtime-attribute
          preemptible: 0
          zones: ${CROMWELL_ZONES}
        }
      }
    }
  }
}

webservice {
  port = ${CROMWELL_PORT}
  interface = 0.0.0.0
  binding-timeout = 5s
  instance.name = "cromwell-server"
}

akka {
  # Allow longer timeout
  # https://gatkforums.broadinstitute.org/gatk/discussion/comment/41714#Comment_41714
  http {
    server {
      request-timeout = 600s
      idle-timeout = 600s
      }
    }
  }

database {
  # mysql example
  profile = "slick.jdbc.MySQLProfile$"
  db {
    driver = "com.mysql.jdbc.Driver"
    url = "jdbc:mysql://${CROMWELL_DB_IP}/cromwell?rewriteBatchedStatements=true"
    # Updte Database user if other than root
    user = "cromwell"
    password = "${CROMWELL_DB_PASS}"
    connectionTimeout = 5000
  }
}